{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_features_from_pcap(pcap_file, window_size=60):\n",
    "    \"\"\"\n",
    "    Extract time-windowed network features from a PCAP file using tshark.\n",
    "    Outputs data in 60-second windows by default.\n",
    "    \n",
    "    Args:\n",
    "        pcap_file: Path to PCAP file\n",
    "        window_size: Size of time window in seconds (default: 60)\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing features for each time window\n",
    "    \"\"\"\n",
    "    print(f\"Processing {pcap_file}...\")\n",
    "    \n",
    "    # Run tshark to extract basic packet info in JSON format\n",
    "    cmd = [\n",
    "        \"tshark\", \n",
    "        \"-r\", pcap_file,\n",
    "        \"-T\", \"json\",\n",
    "        \"-e\", \"frame.time_epoch\", \n",
    "        \"-e\", \"frame.len\",\n",
    "        \"-e\", \"ip.src\", \n",
    "        \"-e\", \"ip.dst\",\n",
    "        \"-e\", \"tcp.srcport\", \n",
    "        \"-e\", \"tcp.dstport\",\n",
    "        \"-e\", \"udp.srcport\", \n",
    "        \"-e\", \"udp.dstport\",\n",
    "        \"-e\", \"_ws.col.Protocol\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error executing tshark: {e}\")\n",
    "        return []\n",
    "    \n",
    "    # Initialize data structures for each time window\n",
    "    windows = defaultdict(lambda: {\n",
    "        'packet_count': 0,\n",
    "        'total_bytes': 0,\n",
    "        'protocols': set(),\n",
    "        'src_ips': set(),\n",
    "        'dst_ips': set(),\n",
    "        'src_ports': set(),\n",
    "        'dst_ports': set()\n",
    "    })\n",
    "    \n",
    "    # Parse JSON output\n",
    "    try:\n",
    "        packets = json.loads(result.stdout)\n",
    "        \n",
    "        # Process each packet\n",
    "        for packet in packets:\n",
    "            if '_source' in packet and 'layers' in packet['_source']:\n",
    "                layers = packet['_source']['layers']\n",
    "                \n",
    "                # Get timestamp and determine window\n",
    "                if 'frame.time_epoch' in layers:\n",
    "                    timestamp = float(layers['frame.time_epoch'][0])\n",
    "                    window_id = int(timestamp // window_size)\n",
    "                    \n",
    "                    # Update packet count\n",
    "                    windows[window_id]['packet_count'] += 1\n",
    "                    \n",
    "                    # Update total bytes\n",
    "                    if 'frame.len' in layers:\n",
    "                        windows[window_id]['total_bytes'] += int(layers['frame.len'][0])\n",
    "                    \n",
    "                    # Update protocol information\n",
    "                    if '_ws.col.Protocol' in layers:\n",
    "                        windows[window_id]['protocols'].add(layers['_ws.col.Protocol'][0])\n",
    "                    \n",
    "                    # Update IP information\n",
    "                    if 'ip.src' in layers:\n",
    "                        windows[window_id]['src_ips'].add(layers['ip.src'][0])\n",
    "                    if 'ip.dst' in layers:\n",
    "                        windows[window_id]['dst_ips'].add(layers['ip.dst'][0])\n",
    "                    \n",
    "                    # Update port information\n",
    "                    if 'tcp.srcport' in layers:\n",
    "                        windows[window_id]['src_ports'].add(layers['tcp.srcport'][0])\n",
    "                    if 'tcp.dstport' in layers:\n",
    "                        windows[window_id]['dst_ports'].add(layers['tcp.dstport'][0])\n",
    "                    if 'udp.srcport' in layers:\n",
    "                        windows[window_id]['src_ports'].add(layers['udp.srcport'][0])\n",
    "                    if 'udp.dstport' in layers:\n",
    "                        windows[window_id]['dst_ports'].add(layers['udp.dstport'][0])\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Could not parse tshark output as JSON\")\n",
    "        return []\n",
    "    \n",
    "    # Convert windows to feature rows\n",
    "    feature_rows = []\n",
    "    for window_id, data in windows.items():\n",
    "        feature_row = {\n",
    "            'window_start': window_id * window_size,\n",
    "            'packet_count': data['packet_count'],\n",
    "            'bytes_per_second': data['total_bytes'] / window_size,\n",
    "            'unique_protocols': len(data['protocols']),\n",
    "            'unique_src_ips': len(data['src_ips']),\n",
    "            'unique_dst_ips': len(data['dst_ips']),\n",
    "            'unique_src_ports': len(data['src_ports']),\n",
    "            'unique_dst_ports': len(data['dst_ports']),\n",
    "            'avg_packet_size': data['total_bytes'] / data['packet_count'] if data['packet_count'] > 0 else 0,\n",
    "            'is_baseline': 'baseline' in pcap_file.lower() #assume the this baseline pcap file has normal traffic.\n",
    "        }\n",
    "        feature_rows.append(feature_row)\n",
    "    \n",
    "    return feature_rows\n",
    "\n",
    "def process_directory(directory, output_csv):\n",
    "    \"\"\"\n",
    "    Process all PCAP files in a directory and save features to CSV\n",
    "    \n",
    "    Args:\n",
    "        directory: Directory containing PCAP files\n",
    "        output_csv: Path to output CSV file\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    \n",
    "    # Process each PCAP file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.pcap'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            features = extract_features_from_pcap(file_path)\n",
    "            all_features.extend(features)\n",
    "    \n",
    "    # Write features to CSV\n",
    "    if all_features:\n",
    "        fieldnames = all_features[0].keys()\n",
    "        with open(output_csv, 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_features)\n",
    "        \n",
    "        print(f\"Successfully extracted features from {len(all_features)} time windows\")\n",
    "        print(f\"Data saved to {output_csv}\")\n",
    "    else:\n",
    "        print(\"No features extracted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/eren/Documents/GitHub/Network-Anomaly-Detection/baseline_day1.pcap...\n",
      "Successfully extracted features from 61 time windows\n",
      "Data saved to day1.csv\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "process_directory(current_directory, \"day1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_extraction(pcap_file, window_size=60):\n",
    "    \"\"\"\n",
    "    Extract time-windowed network features from a PCAP file using tshark.\n",
    "    Outputs data in 60-second windows by default with enhanced features.\n",
    "    \n",
    "    Args:\n",
    "        pcap_file: Path to PCAP file\n",
    "        window_size: Size of time window in seconds (default: 60)\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing features for each time window\n",
    "    \"\"\"\n",
    "    print(f\"Processing {pcap_file}...\")\n",
    "    \n",
    "    # Run tshark to extract more detailed packet info in JSON format\n",
    "    cmd = [\n",
    "        \"tshark\", \n",
    "        \"-r\", pcap_file,\n",
    "        \"-T\", \"json\",\n",
    "        \"-e\", \"frame.time_epoch\", \n",
    "        \"-e\", \"frame.len\",\n",
    "        \"-e\", \"ip.src\", \n",
    "        \"-e\", \"ip.dst\",\n",
    "        \"-e\", \"tcp.srcport\", \n",
    "        \"-e\", \"tcp.dstport\",\n",
    "        \"-e\", \"udp.srcport\", \n",
    "        \"-e\", \"udp.dstport\",\n",
    "        \"-e\", \"_ws.col.Protocol\",\n",
    "        \"-e\", \"tcp.flags\",\n",
    "        \"-e\", \"tcp.analysis.retransmission\",\n",
    "        \"-e\", \"http.request.method\",\n",
    "        \"-e\", \"dns.qry.name\",\n",
    "        \"-e\", \"ip.ttl\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error executing tshark: {e}\")\n",
    "        return []\n",
    "    \n",
    "    # Initialize data structures for each time window\n",
    "    windows = defaultdict(lambda: {\n",
    "        'packet_count': 0,\n",
    "        'total_bytes': 0,\n",
    "        'protocols': set(),\n",
    "        'src_ips': set(),\n",
    "        'dst_ips': set(),\n",
    "        'src_ports': set(),\n",
    "        'dst_ports': set(),\n",
    "        # New data structures for enhanced features\n",
    "        'syn_count': 0,\n",
    "        'fin_count': 0,\n",
    "        'rst_count': 0,\n",
    "        'retransmissions': 0,\n",
    "        'http_methods': defaultdict(int),\n",
    "        'dns_queries': set(),\n",
    "        'ttl_values': [],\n",
    "        'payload_sizes': [],\n",
    "        'ip_pairs': set(),\n",
    "        'port_pairs': set(),\n",
    "        'new_connections': 0,\n",
    "        'unique_ip_port_pairs': set(),\n",
    "        'bytes_in': 0,\n",
    "        'bytes_out': 0,\n",
    "        'packet_count_in': 0,\n",
    "        'packet_count_out': 0,\n",
    "        'internal_ips': set()\n",
    "    })\n",
    "    \n",
    "    # Get the local IP address prefix to distinguish internal/external traffic\n",
    "    local_ip_prefix = '192.168.1.'  # Adjust based on your network\n",
    "    \n",
    "    # Parse JSON output\n",
    "    try:\n",
    "        packets = json.loads(result.stdout)\n",
    "        \n",
    "        # Process each packet\n",
    "        for packet in packets:\n",
    "            if '_source' in packet and 'layers' in packet['_source']:\n",
    "                layers = packet['_source']['layers']\n",
    "                \n",
    "                # Get timestamp and determine window\n",
    "                if 'frame.time_epoch' in layers:\n",
    "                    timestamp = float(layers['frame.time_epoch'][0])\n",
    "                    window_id = int(timestamp // window_size)\n",
    "                    \n",
    "                    # Basic packet information\n",
    "                    windows[window_id]['packet_count'] += 1\n",
    "                    \n",
    "                    # Packet size\n",
    "                    packet_size = 0\n",
    "                    if 'frame.len' in layers:\n",
    "                        packet_size = int(layers['frame.len'][0])\n",
    "                        windows[window_id]['total_bytes'] += packet_size\n",
    "                        windows[window_id]['payload_sizes'].append(packet_size)\n",
    "                    \n",
    "                    # Protocol information\n",
    "                    if '_ws.col.Protocol' in layers:\n",
    "                        windows[window_id]['protocols'].add(layers['_ws.col.Protocol'][0])\n",
    "                    \n",
    "                    # IP information\n",
    "                    src_ip = None\n",
    "                    dst_ip = None\n",
    "                    \n",
    "                    if 'ip.src' in layers:\n",
    "                        src_ip = layers['ip.src'][0]\n",
    "                        windows[window_id]['src_ips'].add(src_ip)\n",
    "                        \n",
    "                        # Track internal IPs\n",
    "                        if src_ip.startswith(local_ip_prefix):\n",
    "                            windows[window_id]['internal_ips'].add(src_ip)\n",
    "                    \n",
    "                    if 'ip.dst' in layers:\n",
    "                        dst_ip = layers['ip.dst'][0]\n",
    "                        windows[window_id]['dst_ips'].add(dst_ip)\n",
    "                        \n",
    "                        # Track internal IPs\n",
    "                        if dst_ip.startswith(local_ip_prefix):\n",
    "                            windows[window_id]['internal_ips'].add(dst_ip)\n",
    "                    \n",
    "                    # Track unique IP pairs\n",
    "                    if src_ip and dst_ip:\n",
    "                        ip_pair = f\"{src_ip}-{dst_ip}\"\n",
    "                        windows[window_id]['ip_pairs'].add(ip_pair)\n",
    "                        \n",
    "                        # Distinguish inbound and outbound traffic\n",
    "                        if src_ip.startswith(local_ip_prefix) and not dst_ip.startswith(local_ip_prefix):\n",
    "                            # Outbound traffic\n",
    "                            windows[window_id]['bytes_out'] += packet_size\n",
    "                            windows[window_id]['packet_count_out'] += 1\n",
    "                        elif dst_ip.startswith(local_ip_prefix) and not src_ip.startswith(local_ip_prefix):\n",
    "                            # Inbound traffic\n",
    "                            windows[window_id]['bytes_in'] += packet_size\n",
    "                            windows[window_id]['packet_count_in'] += 1\n",
    "                    \n",
    "                    # Port information\n",
    "                    src_port = None\n",
    "                    dst_port = None\n",
    "                    \n",
    "                    if 'tcp.srcport' in layers:\n",
    "                        src_port = layers['tcp.srcport'][0]\n",
    "                        windows[window_id]['src_ports'].add(src_port)\n",
    "                    elif 'udp.srcport' in layers:\n",
    "                        src_port = layers['udp.srcport'][0]\n",
    "                        windows[window_id]['src_ports'].add(src_port)\n",
    "                    \n",
    "                    if 'tcp.dstport' in layers:\n",
    "                        dst_port = layers['tcp.dstport'][0]\n",
    "                        windows[window_id]['dst_ports'].add(dst_port)\n",
    "                    elif 'udp.dstport' in layers:\n",
    "                        dst_port = layers['udp.dstport'][0]\n",
    "                        windows[window_id]['dst_ports'].add(dst_port)\n",
    "                    \n",
    "                    # Track unique port pairs\n",
    "                    if src_port and dst_port:\n",
    "                        port_pair = f\"{src_port}-{dst_port}\"\n",
    "                        windows[window_id]['port_pairs'].add(port_pair)\n",
    "                        \n",
    "                        # Track unique IP:port combinations\n",
    "                        if src_ip and dst_ip:\n",
    "                            ip_port_pair = f\"{src_ip}:{src_port}-{dst_ip}:{dst_port}\"\n",
    "                            windows[window_id]['unique_ip_port_pairs'].add(ip_port_pair)\n",
    "                    \n",
    "                    # TCP flags for identifying connection patterns\n",
    "                    if 'tcp.flags' in layers:\n",
    "                        tcp_flags = int(layers['tcp.flags'][0], 16)\n",
    "                        \n",
    "                        # SYN flag (0x02) - Connection establishment\n",
    "                        if tcp_flags & 0x02:\n",
    "                            windows[window_id]['syn_count'] += 1\n",
    "                            windows[window_id]['new_connections'] += 1\n",
    "                        \n",
    "                        # FIN flag (0x01) - Connection termination\n",
    "                        if tcp_flags & 0x01:\n",
    "                            windows[window_id]['fin_count'] += 1\n",
    "                        \n",
    "                        # RST flag (0x04) - Connection reset\n",
    "                        if tcp_flags & 0x04:\n",
    "                            windows[window_id]['rst_count'] += 1\n",
    "                    \n",
    "                    # Retransmissions - indicator of network problems or potential DoS\n",
    "                    if 'tcp.analysis.retransmission' in layers:\n",
    "                        windows[window_id]['retransmissions'] += 1\n",
    "                    \n",
    "                    # HTTP methods - useful for detecting unusual web traffic patterns\n",
    "                    if 'http.request.method' in layers:\n",
    "                        method = layers['http.request.method'][0]\n",
    "                        windows[window_id]['http_methods'][method] += 1\n",
    "                    \n",
    "                    # DNS queries - useful for detecting DNS tunneling or unusual domains\n",
    "                    if 'dns.qry.name' in layers:\n",
    "                        dns_query = layers['dns.qry.name'][0]\n",
    "                        windows[window_id]['dns_queries'].add(dns_query)\n",
    "                    \n",
    "                    # TTL values - unusual TTLs can indicate spoofed packets\n",
    "                    if 'ip.ttl' in layers:\n",
    "                        ttl = int(layers['ip.ttl'][0])\n",
    "                        windows[window_id]['ttl_values'].append(ttl)\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Could not parse tshark output as JSON\")\n",
    "        return []\n",
    "    \n",
    "    # Convert windows to feature rows\n",
    "    feature_rows = []\n",
    "    for window_id, data in windows.items():\n",
    "        # Calculate statistics for numeric lists\n",
    "        ttl_values = data['ttl_values']\n",
    "        ttl_mean = sum(ttl_values) / len(ttl_values) if ttl_values else 0\n",
    "        ttl_std = (sum((x - ttl_mean) ** 2 for x in ttl_values) / len(ttl_values)) ** 0.5 if ttl_values else 0\n",
    "        \n",
    "        payload_sizes = data['payload_sizes']\n",
    "        payload_mean = sum(payload_sizes) / len(payload_sizes) if payload_sizes else 0\n",
    "        payload_std = (sum((x - payload_mean) ** 2 for x in payload_sizes) / len(payload_sizes)) ** 0.5 if payload_sizes else 0\n",
    "        \n",
    "        # Compute traffic ratios\n",
    "        io_bytes_ratio = data['bytes_in'] / data['bytes_out'] if data['bytes_out'] > 0 else 0\n",
    "        io_packet_ratio = data['packet_count_in'] / data['packet_count_out'] if data['packet_count_out'] > 0 else 0\n",
    "        \n",
    "        # Compute connection termination ratio\n",
    "        termination_ratio = (data['fin_count'] + data['rst_count']) / data['syn_count'] if data['syn_count'] > 0 else 0\n",
    "        \n",
    "        # Create feature dictionary\n",
    "        feature_row = {\n",
    "            'window_id': window_id,\n",
    "            'window_start': window_id * window_size,\n",
    "            \n",
    "            # Basic traffic metrics\n",
    "            'packet_count': data['packet_count'],\n",
    "            'bytes_per_second': data['total_bytes'] / window_size,\n",
    "            'avg_packet_size': data['total_bytes'] / data['packet_count'] if data['packet_count'] > 0 else 0,\n",
    "            'packet_size_std': payload_std,\n",
    "            \n",
    "            # Network entities\n",
    "            'unique_protocols': len(data['protocols']),\n",
    "            'unique_src_ips': len(data['src_ips']),\n",
    "            'unique_dst_ips': len(data['dst_ips']),\n",
    "            'unique_src_ports': len(data['src_ports']),\n",
    "            'unique_dst_ports': len(data['dst_ports']),\n",
    "            'unique_ip_pairs': len(data['ip_pairs']),\n",
    "            'unique_port_pairs': len(data['port_pairs']),\n",
    "            'unique_connections': len(data['unique_ip_port_pairs']),\n",
    "            'dns_query_count': len(data['dns_queries']),\n",
    "            \n",
    "            # Traffic direction metrics\n",
    "            'bytes_in': data['bytes_in'],\n",
    "            'bytes_out': data['bytes_out'],\n",
    "            'packets_in': data['packet_count_in'],\n",
    "            'packets_out': data['packet_count_out'],\n",
    "            'io_bytes_ratio': io_bytes_ratio,\n",
    "            'io_packet_ratio': io_packet_ratio,\n",
    "            \n",
    "            # Connection pattern metrics\n",
    "            'new_connections': data['new_connections'],\n",
    "            'syn_count': data['syn_count'],\n",
    "            'fin_count': data['fin_count'],\n",
    "            'rst_count': data['rst_count'],\n",
    "            'syn_fin_ratio': data['syn_count'] / data['fin_count'] if data['fin_count'] > 0 else 0,\n",
    "            'connection_termination_ratio': termination_ratio,\n",
    "            \n",
    "            # Error metrics\n",
    "            'retransmission_count': data['retransmissions'],\n",
    "            'retransmission_rate': data['retransmissions'] / data['packet_count'] if data['packet_count'] > 0 else 0,\n",
    "            \n",
    "            # Network behavior metrics\n",
    "            'internal_external_ratio': len(data['internal_ips']) / (len(data['src_ips']) + len(data['dst_ips']) - len(data['internal_ips'])) if (len(data['src_ips']) + len(data['dst_ips']) - len(data['internal_ips'])) > 0 else 0,\n",
    "            'ttl_mean': ttl_mean,\n",
    "            'ttl_std': ttl_std,\n",
    "            \n",
    "            # HTTP metrics (if present)\n",
    "            'http_get_count': data['http_methods'].get('GET', 0),\n",
    "            'http_post_count': data['http_methods'].get('POST', 0),\n",
    "            'http_other_count': sum(data['http_methods'].values()) - data['http_methods'].get('GET', 0) - data['http_methods'].get('POST', 0),\n",
    "            \n",
    "            # Labels\n",
    "            'is_baseline': 'baseline' in pcap_file.lower(),\n",
    "            'file_source': os.path.basename(pcap_file)\n",
    "        }\n",
    "        \n",
    "        feature_rows.append(feature_row)\n",
    "        \n",
    "    \n",
    "    return feature_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_process(directory, output_csv):\n",
    "    \"\"\"\n",
    "    Process all PCAP files in a directory and save features to CSV\n",
    "    \n",
    "    Args:\n",
    "        directory: Directory containing PCAP files\n",
    "        output_csv: Path to output CSV file\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    \n",
    "    # Process each PCAP file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.pcap'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            features = advanced_extraction(file_path)\n",
    "            all_features.extend(features)\n",
    "    \n",
    "    # Write features to CSV\n",
    "    if all_features:\n",
    "        fieldnames = all_features[0].keys()\n",
    "        with open(output_csv, 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_features)\n",
    "        \n",
    "        print(f\"Successfully extracted features from {len(all_features)} time windows\")\n",
    "        print(f\"Data saved to {output_csv}\")\n",
    "    else:\n",
    "        print(\"No features extracted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/eren/Documents/GitHub/Network-Anomaly-Detection/baseline_day1.pcap...\n",
      "Successfully extracted features from 61 time windows\n",
      "Data saved to day1_advanced.csv\n"
     ]
    }
   ],
   "source": [
    "advanced_process(current_directory, \"day1_advanced.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PackageTracer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
